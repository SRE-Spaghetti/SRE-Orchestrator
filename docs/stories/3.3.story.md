---
Epic: 3
Story: 3
Title: Root Cause Correlation Engine
Status: Draft
---

### Story

As the Orchestrator, I want to use a simple rules engine to correlate the evidence from the Kubernetes Agent with context from the knowledge graph, so that I can generate a suggested root cause.

### Acceptance Criteria

1.  A new "correlation" module is created in the orchestrator.
2.  The module takes the collected evidence (pod status, logs) and the knowledge graph as input.
3.  A few basic correlation rules are implemented, for example:
    *   **Rule 1:** IF a pod's restart count is high AND its logs contain "OOMKilled", THEN the suggested root cause is "Insufficient Memory".
    *   **Rule 2:** IF a pod's status is `Pending` AND its events show "FailedScheduling", THEN the suggested root cause is "Insufficient Cluster Resources".
    *   **Rule 3:** IF a pod's logs show "connection refused" to a database it `depends_on` (from the knowledge graph), THEN the suggested root cause is "Database Unreachable".
4.  The output of the engine is a suggested root cause and a confidence score (e.g., "high", "medium", "low").

### Dev Notes

#### Project Structure
- **Correlation Engine:** Create a new module at `services/orchestrator/app/core/correlation_engine.py`. [Source: `architecture/source-tree.md`]
- **Integration:** The incident creation workflow should be updated to call this new engine after gathering evidence.

#### Data Models
- **Incident Model:** The `Incident` model will be updated to store the `suggested_root_cause` and `confidence_score`. [Source: `architecture/data-models.md`]

#### Previous Story Insights
- This story will use the `evidence` gathered in Epic 2 and the `knowledge_graph` from Story 3.2.

### Tasks / Subtasks

1.  **(AC: 1)** **Create Correlation Engine Module:**
    - Create the file `services/orchestrator/app/core/correlation_engine.py`.
    - Define a `CorrelationEngine` class or a set of functions.
2.  **(AC: 2, 3, 4)** **Implement Correlation Logic:**
    - The main method of the engine should accept the `evidence` dictionary and the `KnowledgeGraphService` instance as arguments.
    - Implement the basic rules as defined in the ACs. This can be a series of `if/elif/else` statements for the MVP.
    - Each rule should check for specific conditions in the evidence (e.g., parsing logs for keywords, checking pod status).
    - The method should return a tuple containing the suggested root cause (string) and a confidence score (string: "high", "medium", "low").
3.  **Update Incident Creation Workflow:**
    - In the incident creation logic (`services/orchestrator/app/core/`), after gathering evidence from the K8s agent, call the new correlation engine.
    - Pass the `evidence` and the `KnowledgeGraphService` to the engine.
    - Store the returned `suggested_root_cause` and `confidence_score` on the incident object.
4.  **Update Data Model:**
    - Add `suggested_root_cause` and `confidence_score` fields to the `Incident` Pydantic model.
5.  **Write Unit Tests:**
    - In `services/orchestrator/tests/unit/`, create a new test file for the `correlation_engine`.
    - Write individual tests for each correlation rule, providing mock `evidence` and a mock `KnowledgeGraphService` to trigger each rule and verify the output.
    - Update the tests for the incident creation workflow to ensure the correlation engine is called and its results are saved.

### QA Results

- **Status:** Not yet reviewed
- **Date:**
- **Reviewed by:**
- **Summary:**
- **Issues Found:**
- **Recommendations:**
